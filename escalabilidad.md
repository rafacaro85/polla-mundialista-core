# AnÃ¡lisis de Escalabilidad â€” Polla Mundialista Core

**Fecha**: Febrero 2026
**Rama analizada**: `main` (commit `b3b636c`)
**MetodologÃ­a**: AnÃ¡lisis estÃ¡tico del cÃ³digo fuente con modelado matemÃ¡tico de carga

---

## Tabla de contenidos

1. [Modelo de carga del sistema](#1-modelo-de-carga-del-sistema)
2. [Cuellos de botella cuantificados](#2-cuellos-de-botella-cuantificados)
3. [Capacidad por escenario](#3-capacidad-por-escenario)
4. [ProyecciÃ³n de volumen de datos](#4-proyecciÃ³n-de-volumen-de-datos)
5. [LÃ­mites de la infraestructura actual](#5-lÃ­mites-de-la-infraestructura-actual)
6. [Mapa de escalabilidad](#6-mapa-de-escalabilidad)
7. [Hoja de ruta de escalado](#7-hoja-de-ruta-de-escalado)

---

## 1. Modelo de carga del sistema

### 1.1 Patrones de trÃ¡fico del Mundial 2026

El trÃ¡fico de una plataforma de predicciones no es uniforme. Hay tres picos bien definidos por dÃ­a de partido:

```
Volumen de requests (normalizado)
â”‚
100% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pico predicciÃ³n (T-5 min)
 80%
 60%                                  â”Œâ”€â”€â”€â”€â”€â”€â”
 40%                          â”Œâ”€â”€â”€â”   â”‚      â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 20% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚   â”‚      â”‚   â”‚
  5%           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”˜      â””â”€â”€â”€â”˜
               â”‚               â”‚                â”‚
             MaÃ±ana         T-30min          FT+0min
                           (predicciones)  (ranking rush)

  T = hora del partido
```

**Comportamiento tÃ­pico de un usuario por dÃ­a de partido:**

| AcciÃ³n | Frecuencia | Endpoint |
|--------|-----------|----------|
| Consultar partidos del dÃ­a | 2-3 veces | `GET /matches` |
| Guardar predicciÃ³n | 1 vez por partido | `POST /predictions` |
| Ver ranking durante partido | 3-5 veces | `GET /leagues/:id/ranking` |
| Ver ranking al terminar partido | 2-3 veces (pico) | `GET /leagues/:id/ranking` |
| Ver ranking global | 1-2 veces | `GET /standings/global` |

**Requests por usuario activo en dÃ­a de partido: ~15-20 requests/dÃ­a**

### 1.2 Escenarios de torneo

El Mundial 2026 tiene fases bien diferenciadas en tÃ©rminos de carga:

| Fase | Partidos/dÃ­a | DuraciÃ³n | Partidos simultÃ¡neos |
|------|-------------|----------|---------------------|
| Grupos (dÃ­as 1-12) | 4 (primeros dÃ­as hasta 8) | 12 dÃ­as | Hasta 4 |
| Grupos (Ãºltima jornada) | 16 simultÃ¡neos | 4 dÃ­as | 16 (peor caso) |
| Octavos | 2 | 4 dÃ­as | 2 |
| Cuartos | 2 | 2 dÃ­as | 2 |
| Semis + Final | 1 | 3 dÃ­as | 1 |

**El peor caso es la Ãºltima jornada de grupos**: 16 partidos simultÃ¡neos a las 2pm â†’ 16 eventos de fin de partido â†’ 16 disparos de `calculatePointsForMatch` en paralelo.

---

## 2. Cuellos de botella cuantificados

### 2.1 Cuello de botella #1 â€” CÃ¡lculo de puntos al finalizar partido (CRÃTICO)

**Archivo**: `apps/api/src/scoring/scoring.service.ts:65-85`

```typescript
for (const prediction of predictions) {
  prediction.points = this.calculatePoints(match, prediction);
  await this.predictionsRepository.save(prediction); // â† 1 UPDATE por fila
}
```

**Modelo matemÃ¡tico:**

Cada `save()` en TypeORM con la configuraciÃ³n actual ejecuta implÃ­citamente un `SELECT` + `UPDATE`. Para `N` usuarios con predicciÃ³n en un partido:

```
Tiempo total = N Ã— (tiempo_SELECT + tiempo_UPDATE + latencia_red_DB)
             = N Ã— (5ms + 10ms + 2ms)
             = N Ã— 17ms
```

| Usuarios registrados | Predicciones por partido (80% participaciÃ³n) | Tiempo de cÃ¡lculo | Conexiones DB en uso |
|---------------------|---------------------------------------------|-------------------|---------------------|
| 500 | 400 | **6.8 s** | 1 (secuencial) |
| 1.000 | 800 | **13.6 s** | 1 (secuencial) |
| 5.000 | 4.000 | **68 s** | 1 (secuencial) |
| 10.000 | 8.000 | **136 s** | 1 (secuencial) |
| 50.000 | 40.000 | **680 s (11 min)** | 1 (secuencial) |

Durante esos segundos/minutos, la Ãºnica conexiÃ³n del scoring estÃ¡ ocupada. El resto del pool (49 conexiones) sigue disponible para otros requests. Sin embargo, **el cron de sincronizaciÃ³n puede disparar este cÃ¡lculo para mÃºltiples partidos simultÃ¡neamente**, multiplicando el impacto:

```
Peor caso: Ãšltima jornada de grupos
= 16 partidos simultÃ¡neos Ã— 4.000 predicciones Ã— 17ms
= 16 cÃ¡lculos en paralelo â† cada uno ocupa 1 conexiÃ³n del pool
= 16 conexiones Ã— 68 segundos = 68 segundos de saturaciÃ³n parcial del pool
```

Con 50.000 usuarios y 16 partidos simultÃ¡neos: **el pool de 50 conexiones queda saturado completamente** durante ~11 minutos. Todos los requests de usuarios durante ese tiempo hacen timeout.

---

### 2.2 Cuello de botella #2 â€” Ranking de liga con 5 queries secuenciales

**Archivo**: `apps/api/src/leagues/leagues.service.ts:786-982`

El mÃ©todo `getLeagueRanking` ejecuta siempre estas 5 queries en secuencia:

```
Q1: SELECT participants (todos los de la liga)          ~10-30ms
Q2: SELECT SUM goals reales (tiebreaker)                ~5-10ms
Q3: SELECT predictions con puntos (JOIN complex)        ~20-100ms
Q4: SELECT bracket points (GROUP BY)                    ~10-30ms
Q5: SELECT bonus points (JOIN + GROUP BY)               ~10-20ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total sin cachÃ©:                                       ~55-190ms por call
```

**TTL de cachÃ©: 20 segundos** para ranking de liga, **30 segundos** para global.

Con 1.000 usuarios activos durante un partido en vivo, todos refrescando el ranking:

```
Requests de ranking en 20 segundos (ventana de TTL):
= 1.000 usuarios Ã— 1 refresh / 30s Ã— 20s = ~667 requests en 20s

DistribuciÃ³n:
- Request #1: Cache MISS â†’ 5 queries (~190ms) â†’ guarda cachÃ©
- Requests #2-667: Cache HIT â†’ 0 queries

â†’ Solo 1 hit a BD por ventana de 20s (en condiciones ideales)
```

**El problema es el "thundering herd"**: cuando el cachÃ© expira, mÃºltiples requests concurrentes llegan al mismo tiempo antes de que el primero guarde el resultado. Si 50 requests llegan en el mismo milisegundo de expiraciÃ³n, los 50 ejecutan las 5 queries = 250 queries simultÃ¡neas para un solo endpoint.

```
Thundering herd en ranking con 1.000 usuarios activos:
= Asumiendo Poisson con Î» = 667/20 = 33 req/s
= Probabilidad de k requests en la ventana de ~1ms de expiraciÃ³n â‰ˆ mÃºltiple

â†’ Estimado: 5-15 requests concurrentes en el momento de expiraciÃ³n del cachÃ©
â†’ = 25-75 queries simultÃ¡neas al expirar el cachÃ© de ranking
â†’ Con 20 ligas activas = potencialmente 500-1.500 queries en el mismo instante
```

---

### 2.3 Cuello de botella #3 â€” Cron de sincronizaciÃ³n bloquea la cuota de API

**Archivo**: `apps/api/src/matches/match-sync.service.ts:24-84`

```typescript
@Cron('*/5 * * * *')  // Cada 5 minutos
async syncLiveMatches() {
  const activeMatches = await this.matchesRepository.find({
    where: { status: Not('FINISHED'), externalId: Not(IsNull()) }
    // â† sin filtro de ventana temporal
  });

  for (const match of activeMatches) {
    await axios.request({ url: 'api-sports.io/fixtures', params: { id: match.externalId } });
    await new Promise(resolve => setTimeout(resolve, 2000)); // throttle 2s
  }
}
```

**AnÃ¡lisis del costo de cuota por fase:**

| Fase | Partidos en estado != FINISHED | Tiempo del cron | Requests a API-SPORTS/dÃ­a |
|------|-------------------------------|-----------------|--------------------------|
| Fase de grupos (inicio) | ~60 | 120s | 60Ã—288 = **17.280** |
| Fase de grupos (fin) | ~30 (ya terminados) | 60s | 30Ã—288 = **8.640** |
| Octavos | ~50 | 100s | 50Ã—288 = **14.400** |
| Final (solo 1 activo) | ~10 (prev. no eliminados) | 20s | 10Ã—288 = **2.880** |

La API-SPORTS en plan bÃ¡sico tiene un lÃ­mite de ~100-1.000 requests/dÃ­a dependiendo del plan. **Con la configuraciÃ³n actual, el sistema excede este lÃ­mite desde el primer dÃ­a de la fase de grupos**, aunque la mayorÃ­a de partidos aÃºn no han comenzado.

**Solapamiento del cron**: Si el cron dura 120s y se dispara cada 300s, hay margen. Pero si hay 90 partidos activos (inicio del torneo + UCL simultÃ¡neo): 90 Ã— 2s = 180s, y con latencia de red podrÃ­a superar los 300s, causando solapamiento.

---

### 2.4 Cuello de botella #4 â€” Pool de conexiones: 50 pero con un proceso Node.js

**Archivo**: `apps/api/src/app.module.ts:117`

```typescript
extra: { max: 50 }
```

Node.js es single-threaded. NestJS procesa requests de forma asÃ­ncrona pero las operaciones de CPU (como la iteraciÃ³n del `calculatePointsForMatch`) no liberan el event loop. Sin embargo, las queries a PostgreSQL sÃ­ son asÃ­ncronas vÃ­a `pg` driver.

**Modelo de concurrencia efectiva:**

```
Capacidad teÃ³rica del pool:
= 50 conexiones Ã— (1000ms / latencia_promedio_query)
= 50 Ã— (1000 / 50ms) = 1.000 queries/segundo (teÃ³rico)

Capacidad real con NestJS (single process):
= Limitado por event loop en operaciones mixtas
= ~200-400 queries/segundo en condiciones reales
```

**El throttler es global a nivel de mÃ³dulo pero POR IP, no total**:

```typescript
ThrottlerModule.forRoot([{ ttl: 60000, limit: 500 }])
```

Esto significa que 500 usuarios pueden enviar 500 req/min cada uno = **250.000 req/min globales** sin activar el throttler. El throttler solo protege contra un Ãºnico usuario agresivo, no contra carga agregada.

---

### 2.5 Cuello de botella #5 â€” `getAllLeagues` sin paginaciÃ³n

**Archivo**: `apps/api/src/leagues/leagues.service.ts:516-554`

```typescript
const leagues = await this.leaguesRepository.find({
  relations: ['creator', 'participants'], // carga TODOS los participantes
});
```

**Crecimiento de memoria por nÃºmero de ligas:**

| Ligas | Participantes promedio | Filas `LeagueParticipant` cargadas | Memoria estimada |
|-------|----------------------|-----------------------------------|-----------------|
| 100 | 15 | 1.500 | ~5 MB |
| 500 | 20 | 10.000 | ~30 MB |
| 1.000 | 25 | 25.000 | ~75 MB |
| 5.000 | 30 | 150.000 | ~450 MB |
| 10.000 | 30 | 300.000 | **~900 MB** â†’ OOM en Railway |

Railway en plan bÃ¡sico tiene **512 MB a 1 GB de RAM**. Con 5.000+ ligas, una sola llamada a `getAllLeagues` puede causar un Out-of-Memory y reiniciar el proceso.

---

### 2.6 Cuello de botella #6 â€” Predicciones: write storm pre-partido

**Archivo**: `apps/api/src/predictions/predictions.service.ts:130-198`

Cada `upsertPrediction` ejecuta para un usuario con liga especÃ­fica:

```
1. SELECT LeagueParticipant (verificar bloqueo)    ~10ms
2. SELECT Match (verificar fecha y lock)            ~5ms
3. SELECT previous jokers (queryBuilder)            ~20ms
4. Para cada joker anterior: SELECT + UPDATE        ~15ms cada uno
5. SELECT predicciÃ³n existente                      ~10ms
6. INSERT/UPDATE predicciÃ³n                         ~15ms
7. SELECT predicciÃ³n global (sync)                  ~10ms
8. INSERT/UPDATE predicciÃ³n global                  ~15ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total por predicciÃ³n: ~100-150ms (sin jokers activos)
                      ~130-200ms (con 1 joker a desactivar)
```

**30 minutos antes del partido â€” pico de predicciones:**

| Usuarios totales | Usuarios que predicen en Ãºltimos 5 min | Requests/seg | Queries/seg | Conexiones necesarias |
|-----------------|----------------------------------------|-------------|------------|----------------------|
| 500 | 250 | 0.83/s | ~8/s | ~1-2 |
| 2.000 | 1.000 | 3.3/s | ~33/s | ~5 |
| 10.000 | 5.000 | 16.7/s | ~167/s | ~25 |
| 25.000 | 12.500 | 41.7/s | ~417/s | **>50 â†’ pool saturado** |

Con **~25.000 usuarios**, el pool de 50 conexiones empieza a saturarse en el pico de predicciones. Con la race condition del joker no resuelta, la situaciÃ³n es peor porque pueden quedar queries colgadas esperando.

---

## 3. Capacidad por escenario

### 3.1 Estado actual (sin ningÃºn cambio)

#### Escenario A: Partido normal â€” Fase de grupos

```
Condiciones: 1 partido, usuarios prediciend durante el dÃ­a, ranking durante el partido

                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚           CAPACIDAD CON ARQUITECTURA ACTUAL             â”‚
                 â”‚                                                         â”‚
 Usuarios        â”‚   Comportamiento esperado                               â”‚
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
 < 1.000         â”‚   âœ… Funciona correctamente                             â”‚
   1.000-3.000   â”‚   âš ï¸  Lentitud al terminar partido (13-51s de scoring) â”‚
   3.000-8.000   â”‚   âŒ Timeouts en ranking post-partido                   â”‚
   8.000-15.000  â”‚   âŒ Pool saturado, errores en masa                     â”‚
   > 15.000      â”‚   ğŸ’€ Crash del servicio o reinicio por OOM              â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**LÃ­mite prÃ¡ctico actual**: ~2.000-3.000 usuarios registrados activos

#### Escenario B: Ãšltima jornada de grupos (16 partidos simultÃ¡neos)

```
Evento: 16 partidos terminan en el mismo margen de ~15 minutos
Efecto: 16 disparos concurrentes de calculatePointsForMatch

Con 2.000 usuarios (caso conservador):
= 16 partidos Ã— 1.600 predicciones Ã— 17ms
= 16 cÃ¡lculos en paralelo, cada uno ~27 segundos
= 16 conexiones del pool ocupadas por 27 segundos cada una
= Pool de 50 con 16 ocupadas â†’ 34 disponibles para usuarios

Resultado: Sistema degradado pero funcional (si no hay mÃ¡s de 1.000 usuarios activos simultÃ¡neos)

Con 5.000 usuarios:
= 16 partidos Ã— 4.000 predicciones Ã— 17ms
= 16 cÃ¡lculos Ã— 68 segundos
= Pool completamente saturado por 68 segundos
= TODO el trÃ¡fico de usuarios hace timeout

â†’ LÃ­mite para este evento: ~1.500 usuarios registrados
```

#### Escenario C: Pico absoluto â€” Final del Mundial

```
Condiciones: 1 partido, mÃ¡xima audiencia, usuarios revisando predicciones constantemente

Supuesto: 50% de usuarios activos simultÃ¡neamente (mÃ¡ximo histÃ³rico en apps de fÃºtbol)
Con 10.000 registrados â†’ 5.000 activos simultÃ¡neos

Requests estimados (10 min antes del partido):
= 5.000 usuarios Ã— 5 requests/10min = 2.500 req/min = 41 req/seg

Queries por segundo:
= 41 req/s Ã— promedio 8 queries/request = 328 queries/seg

Pool de 50 conexiones @ 50ms promedio:
= 50 / 0.050 = 1.000 queries/seg teÃ³rico
= En la prÃ¡ctica: ~400 queries/seg (event loop overhead)

â†’ 328 < 400: Sistema sobrevive en el pico pre-partido

Al terminar el partido (scoring de 5.000 usuarios):
= 4.000 predicciones Ã— 17ms = 68 segundos de scoring
= Durante esos 68 segundos: 1 conexiÃ³n ocupada en scoring
= Resto de usuarios siguen siendo atendidos
= PERO: si hay thundering herd en ranking â†’ 75 queries simultÃ¡neas adicionales

â†’ La Final del Mundial serÃ­a el punto de quiebre entre 3.000-5.000 usuarios
```

### 3.2 Tabla resumen de capacidad

| Contexto | Usuarios mÃ¡ximos antes de degradaciÃ³n | Usuarios mÃ¡ximos antes de falla total |
|----------|--------------------------------------|--------------------------------------|
| DÃ­a sin partidos | **~15.000** (getAllLeagues como lÃ­mite) | ~25.000 |
| Partido normal (1 a la vez) | **~3.000** | ~8.000 |
| Ãšltima jornada grupos (16 simultÃ¡neos) | **~1.500** | ~3.000 |
| Final del Mundial (mÃ¡ximo engagement) | **~3.000-5.000** | ~10.000 |

---

## 4. ProyecciÃ³n de volumen de datos

### 4.1 Crecimiento de tablas crÃ­ticas

#### Tabla `predictions` (la mÃ¡s grande)

Cada usuario genera predicciones en dos contextos (global + liga especÃ­fica):

```
Predicciones por usuario por torneo:
= partidos_torneo Ã— (1 global + N_ligas)

Mundial 2026: 64 partidos
Si promedio de usuario estÃ¡ en 2 ligas:
= 64 Ã— (1 + 2) = 192 predicciones/usuario
```

| Usuarios registrados | Predicciones total (1 liga promedio) | Predicciones (3 ligas promedio) | TamaÃ±o estimado |
|---------------------|--------------------------------------|--------------------------------|-----------------|
| 1.000 | 128.000 | 256.000 | ~15-30 MB |
| 5.000 | 640.000 | 1.280.000 | ~75-150 MB |
| 10.000 | 1.280.000 | 2.560.000 | ~150-300 MB |
| 50.000 | 6.400.000 | 12.800.000 | ~750 MB - 1.5 GB |
| 100.000 | 12.800.000 | 25.600.000 | **~1.5-3 GB** |

#### Tabla `league_participants`

```
Participantes = usuarios Ã— ligas_promedio
Con 5.000 usuarios en 2 ligas promedio = 10.000 filas â†’ insignificante
Con 50.000 usuarios en 2 ligas = 100.000 filas â†’ ~10MB
```

#### Impacto en la query de ranking

La query de ranking hace `JOIN` de `predictions` por `userId IN (:...userIds)` y `tournamentId`:

```sql
-- getLeagueRanking â€” consulta de predicciones
SELECT p.userId, p.matchId, p.points, p.leagueId, p.isJoker
FROM predictions p
INNER JOIN matches m ON m.id = p.matchId
WHERE p.userId IN (:...userIds)       -- 100 usuarios de la liga
  AND (p.leagueId = $1 OR p.leagueId IS NULL)
  AND m.tournamentId = $2
  AND m.status IN ('FINISHED', 'COMPLETED')
```

**Sin Ã­ndice en `tournamentId` de `matches`**: la query hace full scan de matches en el `JOIN`. La entidad `Match` no tiene `@Index` en `tournamentId`, `status`, ni `date`. Con 128 partidos (WC2026 + UCL) el full scan es trivial, pero demuestra que la query no estÃ¡ optimizada para escalar.

**Ãndices existentes en `predictions`**:
```typescript
@Index(['match'])                               // âœ… Ãºtil para scoring
@Index(['user', 'leagueId'])                    // âœ… Ãºtil para pantalla de predicciones
@Index(['user', 'match', 'leagueId'], { unique: true })  // âœ… constraint correcto
```

Falta un Ã­ndice compuesto por `(tournamentId, leagueId, userId)` que serÃ­a el Ã³ptimo para las queries de ranking.

### 4.2 Velocidad de crecimiento durante el torneo

```
Mundial 2026: 64 partidos en 34 dÃ­as (11 junio - 19 julio)
Promedio: ~2 partidos/dÃ­a

Con 10.000 usuarios activos:
= 10.000 usuarios Ã— 2 partidos/dÃ­a Ã— 2 contextos = 40.000 nuevas predicciones/dÃ­a
= 40.000 Ã— 34 dÃ­as = 1.360.000 predicciones al final del torneo

Velocidad de inserciÃ³n: 40.000 / 86.400 = ~0.46 predicciones/segundo promedio
â†’ Completamente manejable para PostgreSQL
```

---

## 5. LÃ­mites de la infraestructura actual

### 5.1 Stack de despliegue

```
Internet
  â”‚
  â–¼
Vercel (Next.js)
  â”‚ REST HTTP
  â–¼
Railway â€” NestJS
  â”‚ pool mÃ¡x 50 conexiones
  â–¼
Railway â€” PostgreSQL
  â”‚
Railway â€” Redis (rankings)
```

### 5.2 Restricciones por capa

#### Railway â€” NestJS (proceso Ãºnico)

| Recurso | ConfiguraciÃ³n actual | LÃ­mite prÃ¡ctico |
|---------|---------------------|----------------|
| Instancias | 1 | 1 (sin clustering configurado) |
| CPU | 1 vCPU (plan bÃ¡sico) | ~400-800 req/seg en I/O bound |
| RAM | 512 MB - 1 GB | OOM a ~5.000 ligas (`getAllLeagues`) |
| Conexiones DB salientes | pool max 50 | 50 concurrentes |
| Proceso Node.js | Single-threaded | CPU-bound bloquea event loop |

#### Railway â€” PostgreSQL

| Recurso | LÃ­mite Railway Hobby | LÃ­mite Railway Pro |
|---------|---------------------|-------------------|
| RAM | 512 MB | 2-8 GB |
| Conexiones mÃ¡ximas | ~100 | ~500 |
| Storage | 1 GB | ilimitado |
| CPU | Compartida | Dedicada |

El pool de 50 conexiones desde NestJS + las queries del seeder CLI + posibles herramientas de administraciÃ³n pueden llegar a las 100 conexiones del plan Hobby.

#### Redis (cachÃ© de rankings)

| Recurso | Estado actual |
|---------|-------------|
| TTL ranking liga | 20 segundos |
| TTL ranking global | 30 segundos |
| Thundering herd protection | âŒ no implementado |
| InvalidaciÃ³n proactiva | âŒ no implementada |
| Datos en cachÃ© | Solo rankings (oportunidad para mÃ¡s) |

#### API-SPORTS (datos en vivo)

| MÃ©trica | SituaciÃ³n actual |
|---------|-----------------|
| Requests/dÃ­a (fase de grupos) | ~17.280 estimados |
| LÃ­mite plan bÃ¡sico | ~100-1.000/dÃ­a |
| Estrategia de batching | âŒ no implementada (1 request por partido) |
| Protocolo ante rate limit | Solo log de warning |

### 5.3 Throttler como falsa protecciÃ³n

```typescript
ThrottlerModule.forRoot([{ ttl: 60000, limit: 500 }])
```

Este throttler funciona **por IP**. Protege contra un solo usuario agresivo, pero no limita la carga agregada. Con 2.000 usuarios enviando 10 requests en 60 segundos cada uno (comportamiento normal), el throttler no se activa para nadie, pero el sistema recibe 20.000 requests por minuto.

---

## 6. Mapa de escalabilidad

### 6.1 Umbral por cantidad de usuarios

```
USUARIOS REGISTRADOS
     â”‚
     â”‚  0 â”€â”€â”€â”€ 500      âœ… ZONA VERDE
     â”‚                   Sistema sin estrÃ©s perceptible.
     â”‚                   Todos los endpoints responden <200ms.
     â”‚                   El cron de scoring tarda <10s.
     â”‚
     â”‚  500 â”€â”€â”€ 2.000   âš¡ ZONA AMARILLA
     â”‚                   Lentitud perceptible al terminar partidos.
     â”‚                   Ranking tarda 1-2s sin cachÃ©.
     â”‚                   El cron de scoring puede tardar 10-30s.
     â”‚                   Sistema estable pero con UX degradada.
     â”‚
     â”‚  2.000 â”€â”€ 5.000  ğŸŸ  ZONA NARANJA
     â”‚                   Timeouts esporÃ¡dicos en picos de partido.
     â”‚                   Ãšltima jornada grupos: fallas en cascada.
     â”‚                   El scoring de un partido puede tardar >1 min.
     â”‚                   Pool de conexiones presionado.
     â”‚
     â”‚  5.000 â”€â”€ 10.000 ğŸ”´ ZONA ROJA
     â”‚                   Fallas frecuentes en eventos de alto trÃ¡fico.
     â”‚                   OOM posible con muchas ligas activas.
     â”‚                   El cron superpuesto causa datos inconsistentes.
     â”‚                   Requiere correcciÃ³n antes de escalar.
     â”‚
     â”‚  > 10.000        ğŸ’€ ZONA CRÃTICA
     â”‚                   La arquitectura actual no soporta este volumen.
     â”‚                   Reinicio por OOM, pool saturado permanentemente.
     â”‚                   Datos inconsistentes por race conditions.
```

### 6.2 Cuello de botella dominante por fase de crecimiento

```
  Usuarios   â”‚  Cuello de botella dominante
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  0 - 500    â”‚  Ninguno perceptible
  500 - 2k   â”‚  Scoring al final de partido (N Ã— 17ms secuencial)
  2k - 5k    â”‚  Pool de 50 conexiones bajo carga simultÃ¡nea
  5k - 10k   â”‚  getAllLeagues sin paginaciÃ³n â†’ OOM
              â”‚  Thundering herd en cachÃ© de rankings
  10k - 50k  â”‚  Single-instance NestJS (CPU bound)
              â”‚  No horizontal scaling
  50k - 100k â”‚  PostgreSQL sin read replicas
              â”‚  Redis como single point of failure
  > 100k     â”‚  Arquitectura requiere rediseÃ±o completo
```

---

## 7. Hoja de ruta de escalado

### Fase 1 â€” De ~500 a ~5.000 usuarios (2-3 semanas)

Estas correcciones eliminan los cuellos de botella actuales sin cambiar la infraestructura.

#### 7.1.1 Bulk update de scoring (impacto: x10 en velocidad de scoring)

**Archivo**: `scoring.service.ts`

Reemplazar el loop secuencial con un Ãºnico bulk update:

```typescript
// Antes: N queries
for (const prediction of predictions) {
  await this.predictionsRepository.save(prediction); // 1 query Ã— N
}

// DespuÃ©s: 1 query
const updates = predictions.map(p => ({
  id: p.id,
  points: this.calculatePoints(match, p)
}));
await this.predictionsRepository.save(updates); // 1 query total (o chunks)
```

**Resultado**: 4.000 predicciones â†’ de 68s a ~500ms (x136 mÃ¡s rÃ¡pido).

#### 7.1.2 Lock de ejecuciÃ³n Ãºnica en el cron (impacto: eliminar duplicaciÃ³n y race condition)

```typescript
private isSyncing = false;

@Cron('*/5 * * * *')
async syncLiveMatches() {
  if (this.isSyncing) return; // lock simple
  this.isSyncing = true;
  try {
    // ... lÃ³gica
  } finally {
    this.isSyncing = false;
  }
}
```

#### 7.1.3 Filtro de ventana temporal en el cron (impacto: reducciÃ³n del 95% en llamadas a API)

```typescript
const activeMatches = await this.matchesRepository.find({
  where: {
    status: Not('FINISHED'),
    externalId: Not(IsNull()),
    date: Between(
      new Date(Date.now() - 3 * 60 * 60 * 1000),  // -3 horas
      new Date(Date.now() + 30 * 60 * 1000)         // +30 minutos
    )
  }
});
```

**Resultado**: De ~17.280 a ~500-1.000 requests/dÃ­a a API-SPORTS durante la fase de grupos.

#### 7.1.4 PaginaciÃ³n en `getAllLeagues` (impacto: elimina riesgo de OOM)

```typescript
async getAllLeagues(tournamentId?: string, page = 1, limit = 50) {
  const [leagues, total] = await this.leaguesRepository.findAndCount({
    take: limit,
    skip: (page - 1) * limit,
    ...
  });
  return { data: leagues, total, page, limit };
}
```

#### 7.1.5 Cache con invalidaciÃ³n proactiva (impacto: elimina thundering herd)

```typescript
// Invalidar cachÃ© cuando termina un partido
async calculatePointsForMatch(matchId: string) {
  // ... cÃ¡lculo ...
  await this.cacheManager.del(`ranking:league:${leagueId}`);
  await this.cacheManager.del(`ranking:global:${tournamentId}`);
}

// TTL mÃ¡s largo con invalidaciÃ³n explÃ­cita
await this.cacheManager.set(cacheKey, result, 10 * 60 * 1000); // 10 minutos
```

#### 7.1.6 Ãndices faltantes en base de datos

```sql
-- Para las queries de ranking (matches)
CREATE INDEX idx_matches_tournament_status ON matches("tournamentId", status);
CREATE INDEX idx_matches_tournament_phase ON matches("tournamentId", phase);

-- Para las queries de predicciones en ranking
CREATE INDEX idx_predictions_tournament_league ON predictions("tournamentId", "league_id");

-- Para el cron (filtro de ventana temporal)
CREATE INDEX idx_matches_date_status ON matches(date, status);
```

**Resultado Fase 1**: Sistema capaz de manejar **5.000-8.000 usuarios** sin degradaciÃ³n en condiciones normales.

---

### Fase 2 â€” De ~5.000 a ~25.000 usuarios (1-2 meses)

#### 7.2.1 Cola de trabajos con BullMQ para scoring

Mover el cÃ¡lculo de puntos a un worker asÃ­ncrono. Al terminar un partido, se encola un job en vez de calcular sÃ­ncronamente:

```typescript
// Cuando el partido termina
await this.scoringQueue.add('calculate-match-points', { matchId });

// Worker separado (puede escalar independientemente)
@Processor('scoring')
class ScoringWorker {
  @Process('calculate-match-points')
  async handle(job: Job) {
    await this.scoringService.calculatePointsForMatch(job.data.matchId);
  }
}
```

**Beneficio**: El cron responde inmediatamente, el scoring ocurre en background sin bloquear el API. MÃºltiples workers pueden procesar partidos en paralelo.

#### 7.2.2 Query optimizada de ranking con una sola SQL

Reemplazar las 5 queries secuenciales con una sola query SQL con CTEs (similar a la ya existente en `getGlobalRanking`):

```sql
WITH
  pred_points AS (
    SELECT userId, SUM(points) as total, ...
    FROM predictions p JOIN matches m ON ...
    WHERE p.userId IN (...) AND m.tournamentId = $1
    GROUP BY userId
  ),
  bracket_points AS (...),
  bonus_points AS (...)
SELECT u.*, COALESCE(pp.total, 0) + COALESCE(bp.total, 0) + COALESCE(bonp.total, 0) as total
FROM users u
LEFT JOIN pred_points pp ON pp.userId = u.id
...
```

**Resultado**: Ranking de 200 participantes en una sola query (~30-80ms vs 190ms actual).

#### 7.2.3 Clustering de Node.js

```typescript
// main.ts â€” activar clustering
import cluster from 'cluster';
import os from 'os';

if (cluster.isPrimary) {
  const workers = os.cpus().length; // 2-4 en Railway Pro
  for (let i = 0; i < workers; i++) cluster.fork();
} else {
  bootstrap();
}
```

**Con 2-4 workers en Railway Pro**: capacidad de CPU multiplicada, el event loop de un worker no bloquea los demÃ¡s.

#### 7.2.4 Reducir pool a un tamaÃ±o sostenible

Con clustering y mÃºltiples workers, cada uno tiene su propio pool. Con 4 workers Ã— 50 conexiones = 200 conexiones â†’ excede el lÃ­mite de PostgreSQL en plan bÃ¡sico.

**CorrecciÃ³n**: Reducir pool por proceso a 12-15 conexiones, o usar PgBouncer como pooler externo.

```typescript
extra: {
  max: 12, // 4 workers Ã— 12 = 48 conexiones totales
}
```

**Resultado Fase 2**: Sistema capaz de manejar **20.000-30.000 usuarios**.

---

### Fase 3 â€” De ~25.000 a ~100.000+ usuarios (3-6 meses)

#### 7.3.1 Read Replica de PostgreSQL

Las queries de ranking y estadÃ­sticas son de solo lectura. Dirigirlas a una rÃ©plica elimina la presiÃ³n en la instancia primaria:

```typescript
// Configurar read replica en TypeORM
TypeOrmModule.forRoot({
  replication: {
    master: { host: process.env.DB_MASTER_HOST, ... },
    slaves: [{ host: process.env.DB_REPLICA_HOST, ... }]
  }
})
```

#### 7.3.2 Materializar rankings en base de datos

En vez de calcular el ranking en tiempo real, mantener una tabla `league_rankings` que se actualiza al terminar cada partido. El endpoint de ranking hace `SELECT * FROM league_rankings WHERE leagueId = $1 ORDER BY rank` â€” una query trivial.

```sql
CREATE TABLE league_rankings (
  leagueId UUID,
  userId UUID,
  rank INT,
  totalPoints INT,
  updatedAt TIMESTAMP,
  PRIMARY KEY (leagueId, userId)
);
CREATE INDEX idx_rankings_league_rank ON league_rankings(leagueId, rank);
```

**Resultado**: Ranking en <5ms independientemente del nÃºmero de participantes o predicciones.

#### 7.3.3 WebSockets para actualizaciones en vivo

Reemplazar el polling de ranking (cada 30s) con push via WebSockets. El servidor notifica a los clientes conectados cuando cambia el ranking. Reduce ~90% del trÃ¡fico de polling durante partidos en vivo.

#### 7.3.4 Separar el sync service en un microservicio independiente

El cron de sincronizaciÃ³n con API-SPORTS no tiene por quÃ© estar en el mismo proceso que el API. Un servicio dedicado (con su propio pool de conexiones) puede manejar el sync sin competir por recursos con las peticiones de usuarios.

**Resultado Fase 3**: Sistema capaz de manejar **100.000+ usuarios** con arquitectura distribuida.

---

## Resumen ejecutivo de escalabilidad

### Capacidad actual

| MÃ©trica | Valor |
|---------|-------|
| **Usuarios cÃ³modos** (sin degradaciÃ³n perceptible) | **~1.000** |
| **Usuarios mÃ¡ximos** (con degradaciÃ³n aceptable) | **~3.000** |
| **Punto de falla** (timeouts y errores en masa) | **~5.000-8.000** |
| **Cuello de botella #1** | Scoring secuencial (N Ã— 17ms por partido) |
| **Cuello de botella #2** | Cron sin ventana temporal (agota cuota API) |
| **Cuello de botella #3** | `getAllLeagues` sin paginaciÃ³n (OOM) |
| **Tiempo de scoring con 5.000 usuarios** | ~68 segundos por partido |
| **Tiempo de scoring con 50.000 usuarios** | ~11 minutos por partido |

### Capacidad proyectada con mejoras

| Fase | Esfuerzo | Capacidad resultante | Cambio de infraestructura |
|------|----------|---------------------|--------------------------|
| **Actual** (sin cambios) | â€” | ~1.000-3.000 usuarios | Railway Hobby |
| **Fase 1** (2-3 semanas) | Bulk scoring, cachÃ© mejorado, paginaciÃ³n, Ã­ndices | ~5.000-8.000 usuarios | Railway Hobby (igual) |
| **Fase 2** (1-2 meses) | BullMQ, ranking en 1 SQL, clustering | ~20.000-30.000 usuarios | Railway Pro ($20-50/mes) |
| **Fase 3** (3-6 meses) | Read replica, rankings materializados, WebSockets | ~100.000+ usuarios | Railway Pro + extras (~$100-300/mes) |

### Veredicto

La aplicaciÃ³n estÃ¡ bien dimensionada para un torneo de comunidad pequeÃ±a (**hasta ~1.000 usuarios**). Para el Mundial 2026 con expectativas de crecimiento orgÃ¡nico:

- **Si se esperan hasta 3.000 usuarios**: el sistema aguanta, con momentos de lentitud en el pico de partidos simultÃ¡neos.
- **Si se esperan 3.000-10.000 usuarios**: la **Fase 1** es obligatoria antes del inicio del torneo. Son cambios de cÃ³digo, sin costo adicional de infraestructura.
- **Si se esperan mÃ¡s de 10.000 usuarios**: la **Fase 2** es necesaria. Requiere Railway Pro (~$20-50/mes adicionales) y 4-6 semanas de desarrollo.

El cambio de mayor impacto con menor esfuerzo es el **bulk update de scoring** (`scoring.service.ts:76-80`): 5 lÃ­neas de cÃ³digo que multiplican por 100 la velocidad del evento mÃ¡s crÃ­tico del sistema.
